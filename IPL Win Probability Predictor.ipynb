{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('matches.csv')\n",
    "deliveries = pd.read_csv('deliveries.csv')\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape,deliveries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the 1st innings,2nd innings score in a particular matchid\n",
    "# lets say match id = 1,so inning 1 score = 207,inning 2 score = 172,in that way\n",
    "\n",
    "totalrun_df = deliveries.groupby(['match_id','inning']).sum()['total_runs'].reset_index()\n",
    "\n",
    "totalrun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing only the first innings,as we will be predicting for the second innnigs\n",
    "\n",
    "totalrun_df = totalrun_df[totalrun_df['inning']==1]\n",
    "totalrun_df['total_runs'] = totalrun_df['total_runs'].apply(lambda x:x+1)\n",
    "totalrun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Merging the total first innings score df with the matches df,\n",
    "where left side merging is done on \"id\" column of the matches\n",
    "and right side merging is done on \"match_id\" column of the totalrun_df\n",
    "\n",
    "This is an inner join. The inner join returns only the rows that have matching values in both tables, \n",
    "in this case, the 'matches' DataFrame and the 'totalrun_df' DataFrame. \n",
    "It returns only the rows where the 'id' column in the \"matches\" DataFrame has a match in the 'match_id' \n",
    "column of the \"totalrun_df\" DataFrame.\n",
    "\n",
    "'''\n",
    "\n",
    "match_df = matches.merge(totalrun_df[['match_id','total_runs']],\n",
    "                       left_on='id',right_on='match_id')\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['team1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\n",
    "    'Sunrisers Hyderabad',\n",
    "    'Mumbai Indians',\n",
    "    'Royal Challengers Bangalore',\n",
    "    'Kolkata Knight Riders',\n",
    "    'Kings XI Punjab',\n",
    "    'Chennai Super Kings',\n",
    "    'Rajasthan Royals',\n",
    "    'Delhi Capitals'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the Delhi Daredevils with Delhi Capitals\n",
    "\n",
    "match_df['team1'] = match_df['team1'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "match_df['team2'] = match_df['team2'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "\n",
    "\n",
    "# replacing the Deccan Chargers with Sunrises Hyderabad\n",
    "\n",
    "match_df['team1'] = match_df['team1'].str.replace('Deccan Chargers','Sunrisers Hyderabad')\n",
    "match_df['team2'] = match_df['team2'].str.replace('Deccan Chargers','Sunrisers Hyderabad')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will consider only frequently occuring teams,\n",
    "# which are mentioned in the teams list\n",
    "\n",
    "match_df = match_df[match_df['team1'].isin(teams)]\n",
    "match_df = match_df[match_df['team2'].isin(teams)]\n",
    "\n",
    "match_df['team1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the matches which resulted in dl method\n",
    "\n",
    "match_df[match_df['dl_applied']==1].style.background_gradient(cmap = 'plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring the rows which were DL method\n",
    "\n",
    "match_df = match_df[match_df['dl_applied']==0]\n",
    "\n",
    "# considering the match_id,city,winner and total runs\n",
    "\n",
    "match_df = match_df[['match_id','city','winner','total_runs']]\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging matchdf with delevieries on match_id\n",
    "\n",
    "delivery_df = match_df.merge(deliveries,on='match_id')\n",
    "\n",
    "delivery_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering the 2nd innings because we have to keep a check on the current score of second innings\n",
    "\n",
    "delivery_df = delivery_df[delivery_df['inning'] == 2]\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So by observation we can observe that in the matchdf we had taken\n",
    "firstinnings total runs,right and in the second case,that is in the \n",
    "delivery dataframe we considered second inning runs,as our main aim\n",
    "is to find the probability of either teams to win or loose,we need \n",
    "current runs and runrate,so for current runs,we can apply groupby\n",
    "on matchid and take the cummulative sum wrt total_runs_y,now,basically\n",
    "totalruns was present in matchdf as well as deliveries_df,but as we merged\n",
    "both the dataframes,it resulted in total_runs_x,and total_runs_y,\n",
    "so total_runs_x is the first innings runs and total_runs_y are the second\n",
    "innings runs,ball by ball,by applying cummulative sum,this becomes \n",
    "current score\n",
    "\n",
    "\n",
    "total_runs_y gives the run scored after each ball,so in the second innings,\n",
    "we want to get the total second innings runs,so we will groupby match id\n",
    "and will apply the cummulative sum\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# current score of particular match\n",
    "\n",
    "delivery_df['current_score'] = delivery_df.groupby('match_id')['total_runs_y'].cumsum()\n",
    "\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs left \n",
    "\n",
    "delivery_df['runs_left'] = delivery_df['total_runs_x']-delivery_df['current_score']\n",
    "\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if one ball is played,then balls left = 120-1 = 119........(1)\n",
    "if two balls are played,then balls left = 120-2 = 118\n",
    "\n",
    "so similarly if over=1,over has 6 balls right,so 1*6 = 6\n",
    "now,ball = 1,so 6+1 = 7,now 126-7 = 119,which is same as (1)\n",
    "\n",
    "so we'll use balls_left = 126-(over*6+current_ball)\n",
    "\n",
    "'''\n",
    "\n",
    "# balls left\n",
    "\n",
    "\n",
    "delivery_df['balls_left'] = 126-(delivery_df['over']*6+delivery_df['ball'])\n",
    "\n",
    "delivery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(delivery_df['player_dismissed'].unique())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filling nan values with \"0\"\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].fillna(\"0\")\n",
    "\n",
    "# now we will convert this player_dismissed col into a boolean col\n",
    "# if the player is not dismissed then it's 0 else its 1\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].apply(lambda x:x if x==\"0\" else \"1\")\n",
    "\n",
    "# converting string to int\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].astype('int')\n",
    "\n",
    "\n",
    "delivery_df['player_dismissed'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wickets left\n",
    "\n",
    "wickets = delivery_df.groupby('match_id')['player_dismissed'].cumsum().values\n",
    "\n",
    "delivery_df['wickets_left'] = 10-wickets\n",
    "\n",
    "delivery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current run rate\n",
    "# It is a common practice to express run rates in cricket as runs per over, so the score is multiplied by 6.\n",
    "\n",
    "delivery_df['cur_run_rate'] = (delivery_df['current_score']*6)/(120-delivery_df['balls_left'])\n",
    "\n",
    "# required run rate\n",
    "\n",
    "delivery_df['req_run_rate'] = (delivery_df['runs_left']*6)/(delivery_df['balls_left'])\n",
    "\n",
    "\n",
    "delivery_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultfun(row):\n",
    "    \n",
    "    return 1 if row['batting_team'] == row['winner'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['result'] = delivery_df.apply(resultfun,axis=1)\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.countplot(delivery_df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = delivery_df[['batting_team','bowling_team','city','runs_left',\n",
    "                        'balls_left','wickets_left','total_runs_x','cur_run_rate',\n",
    "                        'req_run_rate','result']]\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping of null values\n",
    "\n",
    "\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['runs_left', 'balls_left', 'wickets_left', 'total_runs_x',\n",
    "    'cur_run_rate', 'req_run_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['balls_left'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final_df.copy()\n",
    "\n",
    "test = data['result']\n",
    "\n",
    "train = data.drop(['result'],axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train,test,test_size=0.2,random_state=1)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batting team,bowling team and city are categorical columns\n",
    "# they will be converted to numeric using onehot encoder\n",
    "\n",
    "# Define the columns to transform\n",
    "# cols_to_transform = ['batting_team','bowling_team','city']\n",
    "\n",
    "\n",
    "cf = ColumnTransformer(transformers = [\n",
    "    ('tnf1',OneHotEncoder(sparse=False,drop='first'),['batting_team','bowling_team','city'])\n",
    "],remainder='passthrough')\n",
    "\n",
    "# X_train = pd.get_dummies(X_train, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pipeline\n",
    "\n",
    "# lr = LogisticRegression(solver='liblinear')\n",
    "pipe = Pipeline(steps=[\n",
    "    ('step1',cf),\n",
    "    ('step2',LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# fitting the training data\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict_proba(X_test)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Random Forest Classifier\n",
    "\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "pipe2 = Pipeline(steps=[\n",
    "    ('step1',cf),\n",
    "    ('step2',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe2.fit(X_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oth index is loose prob and 1st index is win prob\n",
    "\n",
    "pipe2.predict_proba(X_test)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# I will go with Logistic Regression because i need to \n",
    "# showcase the probability right,even though Random Forest is \n",
    "# giving much accurate result,but RandomForest is being baised\n",
    "# at one side,as you can observe the prob of winning for 10th sample\n",
    "# is shown as 98% and 2% loose prob,this is kind of tooo strong or may\n",
    "# be sometimes unrealistic,so its better to use a model which gives equal \n",
    "# justice towards both side,as we also don't know which team will outperform \n",
    "# and win the game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the logistic regression model\n",
    "import pickle\n",
    "pickle.dump(pipe, open('pipe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
